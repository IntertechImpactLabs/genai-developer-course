{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple RAG System\n",
    "\n",
    "## Retrieval-Augmented Generation Exercise\n",
    "\n",
    "In this exercise, you'll build a RAG system that eliminates AI hallucinations by grounding responses in real product data.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand how RAG prevents hallucinations\n",
    "- Implement keyword-based retrieval\n",
    "- See the impact of context on AI responses\n",
    "- Compare accuracy with and without RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Load Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock product catalog with intentionally distinct keywords\n",
    "products = [\n",
    "    {\n",
    "        \"name\": \"TurboCache Pro\",\n",
    "        \"description\": \"Lightning-fast in-memory caching solution with sub-millisecond latency\",\n",
    "        \"features\": [\"10GB capacity\", \"LRU eviction\", \"distributed mode\", \"Redis compatible\"],\n",
    "        \"keywords\": [\"speed\", \"fast\", \"performance\", \"cache\", \"memory\", \"quick\", \"turbo\"],\n",
    "        \"price\": \"$99/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SecureVault Enterprise\",\n",
    "        \"description\": \"Military-grade encryption for sensitive data protection\",\n",
    "        \"features\": [\"AES-256 encryption\", \"biometric auth\", \"SOC2 compliant\", \"key rotation\"],\n",
    "        \"keywords\": [\"security\", \"encryption\", \"protection\", \"vault\", \"safe\", \"secure\", \"privacy\"],\n",
    "        \"price\": \"$199/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CloudSync Manager\",\n",
    "        \"description\": \"Real-time data synchronization across cloud platforms\",\n",
    "        \"features\": [\"Multi-cloud support\", \"version control\", \"1TB storage\", \"automatic backups\"],\n",
    "        \"keywords\": [\"sync\", \"cloud\", \"backup\", \"storage\", \"synchronization\", \"replication\"],\n",
    "        \"price\": \"$149/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DataFlow Analytics\",\n",
    "        \"description\": \"Stream processing and real-time analytics platform\",\n",
    "        \"features\": [\"Apache Kafka integration\", \"ML pipelines\", \"custom dashboards\", \"alerting\"],\n",
    "        \"keywords\": [\"analytics\", \"data\", \"streaming\", \"metrics\", \"insights\", \"dashboard\"],\n",
    "        \"price\": \"$299/month\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(products)} products\")\n",
    "for p in products:\n",
    "    print(f\"  - {p['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Query Without RAG (Observe Hallucination)\n",
    "\n",
    "First, let's see what happens when AI doesn't have access to our product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai_without_context(question):\n",
    "    \"\"\"Simulate AI response without any context\"\"\"\n",
    "    # In real implementation, this would call OpenAI/Claude API\n",
    "    # For demo, we'll show typical hallucinated response\n",
    "    \n",
    "    if \"TurboCache\" in question:\n",
    "        return \"\"\"\n",
    "Based on my knowledge, TurboCache Pro includes:\n",
    "- Advanced ML-based caching algorithms\n",
    "- Automatic scaling to 100TB\n",
    "- Built-in blockchain verification\n",
    "- Quantum-resistant encryption\n",
    "- Free tier available\n",
    "\n",
    "Note: These features are likely made up since I don't have real product information.\n",
    "\"\"\"\n",
    "    else:\n",
    "        return \"I don't have specific information about that product.\"\n",
    "\n",
    "# Test query without RAG\n",
    "response = ask_ai_without_context(\"What features does TurboCache Pro have?\")\n",
    "print(\"WITHOUT RAG (Hallucinated Response):\")\n",
    "print(\"=\" * 50)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Simple Keyword Search\n",
    "\n",
    "Now let's implement a basic retrieval system using keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_products(query, products, threshold=1):\n",
    "    \"\"\"\n",
    "    Simple keyword search - returns products matching query terms\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "        products: List of product dictionaries\n",
    "        threshold: Minimum number of keyword matches required\n",
    "    \n",
    "    Returns:\n",
    "        List of matching products\n",
    "    \"\"\"\n",
    "    # Convert query to lowercase and split into words\n",
    "    query_words = query.lower().split()\n",
    "    \n",
    "    matches = []\n",
    "    for product in products:\n",
    "        # Count how many query words match product keywords\n",
    "        match_count = sum(\n",
    "            1 for word in query_words \n",
    "            if word in product['keywords']\n",
    "        )\n",
    "        \n",
    "        # Include product if it meets threshold\n",
    "        if match_count >= threshold:\n",
    "            matches.append({\n",
    "                'product': product,\n",
    "                'relevance': match_count\n",
    "            })\n",
    "    \n",
    "    # Sort by relevance (most matches first)\n",
    "    matches.sort(key=lambda x: x['relevance'], reverse=True)\n",
    "    \n",
    "    return [m['product'] for m in matches]\n",
    "\n",
    "# Test the search function\n",
    "test_queries = [\n",
    "    \"fast performance\",\n",
    "    \"security encryption\",\n",
    "    \"cloud backup\",\n",
    "    \"data analytics\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_products(query, products)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Found: {[r['name'] for r in results]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Create Context from Search Results\n",
    "\n",
    "Format the search results into context that can be injected into the AI prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(search_results):\n",
    "    \"\"\"Format search results into context for the AI\"\"\"\n",
    "    if not search_results:\n",
    "        return \"No product information available.\"\n",
    "    \n",
    "    context = \"Product Information:\\n\\n\"\n",
    "    for product in search_results:\n",
    "        context += f\"Product: {product['name']}\\n\"\n",
    "        context += f\"Description: {product['description']}\\n\"\n",
    "        context += f\"Features: {', '.join(product['features'])}\\n\"\n",
    "        context += f\"Price: {product['price']}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Example: Create context for \"fast cache\" query\n",
    "results = search_products(\"fast cache\", products)\n",
    "context = create_context(results)\n",
    "print(\"CONTEXT TO INJECT:\")\n",
    "print(\"=\" * 50)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Query With RAG (Accurate Response)\n",
    "\n",
    "Now let's combine search and context to provide accurate, grounded responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai_with_rag(question, products):\n",
    "    \"\"\"Use RAG to provide accurate response\"\"\"\n",
    "    \n",
    "    # Step 1: Search for relevant products\n",
    "    search_results = search_products(question, products)\n",
    "    \n",
    "    # Step 2: Create context from results\n",
    "    context = create_context(search_results)\n",
    "    \n",
    "    # Step 3: Build augmented prompt\n",
    "    prompt = f\"\"\"Based on the following product information:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer based only on the provided information. If the information doesn't answer the question, say so.\"\"\"\n",
    "    \n",
    "    # In real implementation, send this prompt to OpenAI/Claude\n",
    "    # For demo, we'll create an accurate response based on context\n",
    "    \n",
    "    if not search_results:\n",
    "        return \"I couldn't find any products matching your query. Please try different search terms.\"\n",
    "    \n",
    "    # Simulate accurate response based on actual data\n",
    "    if \"TurboCache\" in question and search_results:\n",
    "        return f\"\"\"Based on the provided information, TurboCache Pro includes:\n",
    "- {', '.join(search_results[0]['features'])}\n",
    "- Price: {search_results[0]['price']}\n",
    "\n",
    "These are the actual features from our product catalog.\"\"\"\n",
    "    \n",
    "    # Generic response showing found products\n",
    "    product_names = [p['name'] for p in search_results[:2]]\n",
    "    return f\"Found relevant products: {', '.join(product_names)}. {search_results[0]['description']}\"\n",
    "\n",
    "# Test with RAG\n",
    "response = ask_ai_with_rag(\"What features does TurboCache Pro have?\", products)\n",
    "print(\"WITH RAG (Accurate Response):\")\n",
    "print(\"=\" * 50)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare Different Queries\n",
    "\n",
    "Let's test how different search terms retrieve different context and affect the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries that should match different products\n",
    "test_queries = [\n",
    "    \"I need something fast\",           # Should find TurboCache\n",
    "    \"I need security\",                  # Should find SecureVault  \n",
    "    \"cloud backup solution\",            # Should find CloudSync\n",
    "    \"real-time data processing\",        # Should find DataFlow\n",
    "    \"quantum computing\",                # Should find nothing\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_products(query, products, threshold=1)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Matches: {[r['name'] for r in results] if results else 'No matches'}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Handle Edge Cases\n",
    "\n",
    "A production RAG system needs to handle various edge cases gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai_with_rag_improved(question, products):\n",
    "    \"\"\"Improved RAG with better edge case handling\"\"\"\n",
    "    \n",
    "    search_results = search_products(question, products)\n",
    "    \n",
    "    if not search_results:\n",
    "        # No results found - be honest about it\n",
    "        available = [p['name'] for p in products]\n",
    "        return f\"\"\"I couldn't find any products matching '{question}'. \n",
    "        \n",
    "Available products: {', '.join(available)}\n",
    "        \n",
    "Please try different search terms or ask about a specific product.\"\"\"\n",
    "    \n",
    "    if len(search_results) > 2:\n",
    "        # Too many results - ask for clarification\n",
    "        product_names = [p['name'] for p in search_results]\n",
    "        return f\"\"\"Multiple products match your query: {', '.join(product_names)}. \n",
    "        \n",
    "Please be more specific about which one you're interested in.\"\"\"\n",
    "    \n",
    "    # Good match - provide detailed information\n",
    "    context = create_context(search_results)\n",
    "    return f\"Based on our catalog:\\n\\n{context}\"\n",
    "\n",
    "# Test edge cases\n",
    "print(\"Edge Case 1: No matches\")\n",
    "print(ask_ai_with_rag_improved(\"quantum blockchain AI\", products))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Edge Case 2: Too many matches\")\n",
    "print(ask_ai_with_rag_improved(\"data\", products))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Edge Case 3: Good match\")\n",
    "print(ask_ai_with_rag_improved(\"fast caching\", products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Improve Search Relevance\n",
    "\n",
    "Try implementing more sophisticated search strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_search(query, products):\n",
    "    \"\"\"\n",
    "    Implement a more sophisticated search:\n",
    "    - Partial word matching (e.g., \"sec\" matches \"security\")\n",
    "    - Check product names and descriptions too\n",
    "    - Weight matches by location (name > keywords > description)\n",
    "    \"\"\"\n",
    "    query_words = query.lower().split()\n",
    "    matches = []\n",
    "    \n",
    "    for product in products:\n",
    "        score = 0\n",
    "        \n",
    "        # Check product name (highest weight)\n",
    "        for word in query_words:\n",
    "            if word in product['name'].lower():\n",
    "                score += 3\n",
    "        \n",
    "        # Check keywords (medium weight)\n",
    "        for word in query_words:\n",
    "            if any(word in kw for kw in product['keywords']):\n",
    "                score += 2\n",
    "        \n",
    "        # Check description (lower weight)\n",
    "        for word in query_words:\n",
    "            if word in product['description'].lower():\n",
    "                score += 1\n",
    "        \n",
    "        if score > 0:\n",
    "            matches.append({'product': product, 'score': score})\n",
    "    \n",
    "    # Sort by score\n",
    "    matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return [m['product'] for m in matches]\n",
    "\n",
    "# Test advanced search\n",
    "print(\"Basic search for 'sec':\")\n",
    "print([p['name'] for p in search_products(\"sec\", products)])\n",
    "print()\n",
    "print(\"Advanced search for 'sec':\")\n",
    "print([p['name'] for p in advanced_search(\"sec\", products)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **RAG eliminates hallucinations** by grounding AI responses in real data\n",
    "2. **Simple keyword search** can be surprisingly effective for structured data\n",
    "3. **Context quality matters** - better search means better answers\n",
    "4. **Edge case handling** is crucial for production systems\n",
    "\n",
    "### When to Use RAG\n",
    "\n",
    "✅ **Perfect for:**\n",
    "- Product catalogs and documentation\n",
    "- Company knowledge bases\n",
    "- Dynamic or frequently changing data\n",
    "- Domain-specific information\n",
    "\n",
    "❌ **Not needed for:**\n",
    "- General programming knowledge\n",
    "- Well-known facts\n",
    "- Creative writing tasks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In production, you would:\n",
    "1. Use semantic search with embeddings for better matching\n",
    "2. Implement proper chunking for large documents\n",
    "3. Add a vector database for scale\n",
    "4. Monitor retrieval quality and user satisfaction\n",
    "5. Implement feedback loops for continuous improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}