{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Building a Simple RAG System\n\n## Retrieval-Augmented Generation Exercise\n\nIn this exercise, you'll build a RAG system that provides domain-specific context to AI models using your actual product data.\n\n### Learning Objectives\n- Understand how RAG provides domain-specific context\n- Implement keyword-based retrieval\n- See the impact of context on AI responses\n- Compare accuracy with and without RAG"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Load Mock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock product catalog with intentionally distinct keywords\n",
    "products = [\n",
    "    {\n",
    "        \"name\": \"TurboCache Pro\",\n",
    "        \"description\": \"Lightning-fast in-memory caching solution with sub-millisecond latency\",\n",
    "        \"features\": [\"10GB capacity\", \"LRU eviction\", \"distributed mode\", \"Redis compatible\"],\n",
    "        \"keywords\": [\"speed\", \"fast\", \"performance\", \"cache\", \"memory\", \"quick\", \"turbo\"],\n",
    "        \"price\": \"$99/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SecureVault Enterprise\",\n",
    "        \"description\": \"Military-grade encryption for sensitive data protection\",\n",
    "        \"features\": [\"AES-256 encryption\", \"biometric auth\", \"SOC2 compliant\", \"key rotation\"],\n",
    "        \"keywords\": [\"security\", \"encryption\", \"protection\", \"vault\", \"safe\", \"secure\", \"privacy\"],\n",
    "        \"price\": \"$199/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CloudSync Manager\",\n",
    "        \"description\": \"Real-time data synchronization across cloud platforms\",\n",
    "        \"features\": [\"Multi-cloud support\", \"version control\", \"1TB storage\", \"automatic backups\"],\n",
    "        \"keywords\": [\"sync\", \"cloud\", \"backup\", \"storage\", \"synchronization\", \"replication\"],\n",
    "        \"price\": \"$149/month\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DataFlow Analytics\",\n",
    "        \"description\": \"Stream processing and real-time analytics platform\",\n",
    "        \"features\": [\"Apache Kafka integration\", \"ML pipelines\", \"custom dashboards\", \"alerting\"],\n",
    "        \"keywords\": [\"analytics\", \"data\", \"streaming\", \"metrics\", \"insights\", \"dashboard\"],\n",
    "        \"price\": \"$299/month\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(products)} products\")\n",
    "for p in products:\n",
    "    print(f\"  - {p['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: Query Without RAG (Observe Knowledge Gap)\n\nFirst, let's see what happens when AI doesn't have access to your product information."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Try to import OpenAI for real LLM calls\ntry:\n    from openai import OpenAI\n    OPENAI_AVAILABLE = bool(os.getenv('OPENAI_API_KEY'))\n    if OPENAI_AVAILABLE:\n        client = OpenAI()\n        print(\"✅ OpenAI configured - will use real LLM\")\n    else:\n        print(\"⚠️ Set OPENAI_API_KEY in .env file to use real LLM responses\")\nexcept ImportError:\n    OPENAI_AVAILABLE = False\n    print(\"⚠️ OpenAI not installed. Run: pip install openai\")\n\ndef ask_ai_without_context(question):\n    \"\"\"Ask AI without any context - it lacks domain knowledge!\"\"\"\n    \n    if OPENAI_AVAILABLE:\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[{\"role\": \"user\", \"content\": question}],\n                temperature=0.7\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            print(f\"API error: {e}\")\n            return show_mock_response()\n    else:\n        return show_mock_response()\n\ndef show_mock_response():\n    return \"\"\"\nI don't have specific information about TurboCache Pro in my training data.\nBased on the name, it might be a caching solution, but I cannot provide\naccurate details about its features, pricing, or specifications without\naccess to your product information.\n\nNote: This demonstrates the knowledge gap - AI needs your domain-specific data!\"\"\"\n\n# Test query without RAG\nresponse = ask_ai_without_context(\"What features does TurboCache Pro have?\")\nprint(\"WITHOUT RAG (Knowledge Gap):\")\nprint(\"=\" * 50)\nprint(response)\nprint(\"\\n⚠️ The AI lacks knowledge of your specific products!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Build Simple Keyword Search\n",
    "\n",
    "Now let's implement a basic retrieval system using keyword matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_products(query, products, threshold=1):\n",
    "    \"\"\"\n",
    "    Simple keyword search - returns products matching query terms\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "        products: List of product dictionaries\n",
    "        threshold: Minimum number of keyword matches required\n",
    "    \n",
    "    Returns:\n",
    "        List of matching products\n",
    "    \"\"\"\n",
    "    # Convert query to lowercase and split into words\n",
    "    query_words = query.lower().split()\n",
    "    \n",
    "    matches = []\n",
    "    for product in products:\n",
    "        # Count how many query words match product keywords\n",
    "        match_count = sum(\n",
    "            1 for word in query_words \n",
    "            if word in product['keywords']\n",
    "        )\n",
    "        \n",
    "        # Include product if it meets threshold\n",
    "        if match_count >= threshold:\n",
    "            matches.append({\n",
    "                'product': product,\n",
    "                'relevance': match_count\n",
    "            })\n",
    "    \n",
    "    # Sort by relevance (most matches first)\n",
    "    matches.sort(key=lambda x: x['relevance'], reverse=True)\n",
    "    \n",
    "    return [m['product'] for m in matches]\n",
    "\n",
    "# Test the search function\n",
    "test_queries = [\n",
    "    \"fast performance\",\n",
    "    \"security encryption\",\n",
    "    \"cloud backup\",\n",
    "    \"data analytics\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_products(query, products)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Found: {[r['name'] for r in results]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Create Context from Search Results\n",
    "\n",
    "Format the search results into context that can be injected into the AI prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(search_results):\n",
    "    \"\"\"Format search results into context for the AI\"\"\"\n",
    "    if not search_results:\n",
    "        return \"No product information available.\"\n",
    "    \n",
    "    context = \"Product Information:\\n\\n\"\n",
    "    for product in search_results:\n",
    "        context += f\"Product: {product['name']}\\n\"\n",
    "        context += f\"Description: {product['description']}\\n\"\n",
    "        context += f\"Features: {', '.join(product['features'])}\\n\"\n",
    "        context += f\"Price: {product['price']}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Example: Create context for \"fast cache\" query\n",
    "results = search_products(\"fast cache\", products)\n",
    "context = create_context(results)\n",
    "print(\"CONTEXT TO INJECT:\")\n",
    "print(\"=\" * 50)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5: Query With RAG (Domain-Specific Response)\n\nNow let's combine search and context to provide accurate, domain-specific responses."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def ask_ai_with_rag(question, products):\n    \"\"\"Use RAG to provide domain-specific response\"\"\"\n    \n    # Step 1: Search for relevant products\n    search_results = search_products(question, products)\n    \n    # Step 2: Create context from results\n    context = create_context(search_results)\n    \n    # Step 3: Build augmented prompt\n    prompt = f\"\"\"Based on the following product information:\n\n{context}\n\nQuestion: {question}\n\nAnswer based only on the provided information. If the information doesn't answer the question, say so.\"\"\"\n    \n    if not search_results:\n        return \"I couldn't find any products matching your query. Please try different search terms.\"\n    \n    # Use real LLM if available\n    if OPENAI_AVAILABLE:\n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"Answer based only on the provided context.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.3\n            )\n            return response.choices[0].message.content\n        except Exception as e:\n            print(f\"API error: {e}\")\n            # Fall back to mock response\n    \n    # Mock response when API not available\n    if \"TurboCache\" in question and search_results:\n        return f\"\"\"Based on the provided information, TurboCache Pro includes:\n- {', '.join(search_results[0]['features'])}\n- Price: {search_results[0]['price']}\n\nThese are the actual features from your product catalog.\"\"\"\n    \n    product_names = [p['name'] for p in search_results[:2]]\n    return f\"Found relevant products: {', '.join(product_names)}. {search_results[0]['description']}\"\n\n# Test with RAG\nresponse = ask_ai_with_rag(\"What features does TurboCache Pro have?\", products)\nprint(\"WITH RAG (Domain-Specific Response):\")\nprint(\"=\" * 50)\nprint(response)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare Different Queries\n",
    "\n",
    "Let's test how different search terms retrieve different context and affect the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries that should match different products\n",
    "test_queries = [\n",
    "    \"I need something fast\",           # Should find TurboCache\n",
    "    \"I need security\",                  # Should find SecureVault  \n",
    "    \"cloud backup solution\",            # Should find CloudSync\n",
    "    \"real-time data processing\",        # Should find DataFlow\n",
    "    \"quantum computing\",                # Should find nothing\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_products(query, products, threshold=1)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Matches: {[r['name'] for r in results] if results else 'No matches'}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Handle Edge Cases\n",
    "\n",
    "A production RAG system needs to handle various edge cases gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai_with_rag_improved(question, products):\n",
    "    \"\"\"Improved RAG with better edge case handling\"\"\"\n",
    "    \n",
    "    search_results = search_products(question, products)\n",
    "    \n",
    "    if not search_results:\n",
    "        # No results found - be honest about it\n",
    "        available = [p['name'] for p in products]\n",
    "        return f\"\"\"I couldn't find any products matching '{question}'. \n",
    "        \n",
    "Available products: {', '.join(available)}\n",
    "        \n",
    "Please try different search terms or ask about a specific product.\"\"\"\n",
    "    \n",
    "    if len(search_results) > 2:\n",
    "        # Too many results - ask for clarification\n",
    "        product_names = [p['name'] for p in search_results]\n",
    "        return f\"\"\"Multiple products match your query: {', '.join(product_names)}. \n",
    "        \n",
    "Please be more specific about which one you're interested in.\"\"\"\n",
    "    \n",
    "    # Good match - provide detailed information\n",
    "    context = create_context(search_results)\n",
    "    return f\"Based on our catalog:\\n\\n{context}\"\n",
    "\n",
    "# Test edge cases\n",
    "print(\"Edge Case 1: No matches\")\n",
    "print(ask_ai_with_rag_improved(\"quantum blockchain AI\", products))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Edge Case 2: Too many matches\")\n",
    "print(ask_ai_with_rag_improved(\"data\", products))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Edge Case 3: Good match\")\n",
    "print(ask_ai_with_rag_improved(\"fast caching\", products))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Improve Search Relevance\n",
    "\n",
    "Try implementing more sophisticated search strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_search(query, products):\n",
    "    \"\"\"\n",
    "    Implement a more sophisticated search:\n",
    "    - Partial word matching (e.g., \"sec\" matches \"security\")\n",
    "    - Check product names and descriptions too\n",
    "    - Weight matches by location (name > keywords > description)\n",
    "    \"\"\"\n",
    "    query_words = query.lower().split()\n",
    "    matches = []\n",
    "    \n",
    "    for product in products:\n",
    "        score = 0\n",
    "        \n",
    "        # Check product name (highest weight)\n",
    "        for word in query_words:\n",
    "            if word in product['name'].lower():\n",
    "                score += 3\n",
    "        \n",
    "        # Check keywords (medium weight)\n",
    "        for word in query_words:\n",
    "            if any(word in kw for kw in product['keywords']):\n",
    "                score += 2\n",
    "        \n",
    "        # Check description (lower weight)\n",
    "        for word in query_words:\n",
    "            if word in product['description'].lower():\n",
    "                score += 1\n",
    "        \n",
    "        if score > 0:\n",
    "            matches.append({'product': product, 'score': score})\n",
    "    \n",
    "    # Sort by score\n",
    "    matches.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return [m['product'] for m in matches]\n",
    "\n",
    "# Test advanced search\n",
    "print(\"Basic search for 'sec':\")\n",
    "print([p['name'] for p in search_products(\"sec\", products)])\n",
    "print()\n",
    "print(\"Advanced search for 'sec':\")\n",
    "print([p['name'] for p in advanced_search(\"sec\", products)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary and Key Takeaways\n\n### What We Learned\n\n1. **RAG provides domain-specific context** enabling AI to work with your proprietary data\n2. **Simple keyword search** can be surprisingly effective for structured data\n3. **Context quality matters** - better search means better answers\n4. **Edge case handling** is crucial for production systems\n\n### When to Use RAG\n\n✅ **Perfect for:**\n- Product catalogs and documentation\n- Company knowledge bases\n- Dynamic or frequently changing data\n- Domain-specific and proprietary information\n\n❌ **Not needed for:**\n- General programming knowledge\n- Well-known facts\n- Creative writing tasks\n\n### Next Steps\n\nIn production, you would:\n1. Use semantic search with embeddings for better matching\n2. Implement proper chunking for large documents\n3. Add a vector database for scale\n4. Monitor retrieval quality and user satisfaction\n5. Implement feedback loops for continuous improvement"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}